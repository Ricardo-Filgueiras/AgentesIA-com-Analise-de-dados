{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c7220ee",
   "metadata": {},
   "source": [
    "# Carregando e visualizando dados no Google Colab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "005273c7",
   "metadata": {},
   "source": [
    "Vamos começar entendendo como um LLM (grande modelo de linguagem) pode nos auxiliar, por exemplo, gerando um código para analisar um arquivo. Iniciaremos no Google Colab carregando os dados da empresa. Para isso, importaremos a biblioteca Pandas, voltada para análise de dados, com o comando:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ea640272",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    " \n",
    "GOOGLE_API_KEY = str(os.getenv(\"GOOGLE_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "429163a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Google API Key: 39\n"
     ]
    }
   ],
   "source": [
    "print(\"Google API Key:\", len(GOOGLE_API_KEY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebfa51aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://raw.githubusercontent.com/Ricardo-Filgueiras/AgentesIA-com-Analise-de-dados/refs/heads/main/database/dados_entregas.csv' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0241a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b13a3f21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_pedido</th>\n",
       "      <th>anos_experiencia_agente</th>\n",
       "      <th>classificacao_agente</th>\n",
       "      <th>latitude_loja</th>\n",
       "      <th>longitude_loja</th>\n",
       "      <th>latitude_entrega</th>\n",
       "      <th>longitude_entrega</th>\n",
       "      <th>data_pedido</th>\n",
       "      <th>hora_pedido</th>\n",
       "      <th>hora_retirada</th>\n",
       "      <th>clima</th>\n",
       "      <th>trafego</th>\n",
       "      <th>veiculo</th>\n",
       "      <th>area</th>\n",
       "      <th>categoria_produto</th>\n",
       "      <th>tempo_entrega</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ialx566343618</td>\n",
       "      <td>8</td>\n",
       "      <td>4.9</td>\n",
       "      <td>22.745049</td>\n",
       "      <td>75.892471</td>\n",
       "      <td>22.765049</td>\n",
       "      <td>75.912471</td>\n",
       "      <td>2022-03-19</td>\n",
       "      <td>11:30:00</td>\n",
       "      <td>11:45:00</td>\n",
       "      <td>Ensolarado</td>\n",
       "      <td>Alto</td>\n",
       "      <td>Motocicleta</td>\n",
       "      <td>Urbano</td>\n",
       "      <td>Roupas</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>akqg208421122</td>\n",
       "      <td>10</td>\n",
       "      <td>4.5</td>\n",
       "      <td>12.913041</td>\n",
       "      <td>77.683237</td>\n",
       "      <td>13.043041</td>\n",
       "      <td>77.813237</td>\n",
       "      <td>2022-03-25</td>\n",
       "      <td>19:45:00</td>\n",
       "      <td>19:50:00</td>\n",
       "      <td>Chuvoso</td>\n",
       "      <td>Congestionamento</td>\n",
       "      <td>Scooter</td>\n",
       "      <td>Metropolitano</td>\n",
       "      <td>Eletronicos</td>\n",
       "      <td>165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>njpu434582536</td>\n",
       "      <td>16</td>\n",
       "      <td>4.4</td>\n",
       "      <td>12.914264</td>\n",
       "      <td>77.678400</td>\n",
       "      <td>12.924264</td>\n",
       "      <td>77.688400</td>\n",
       "      <td>2022-03-19</td>\n",
       "      <td>08:30:00</td>\n",
       "      <td>08:45:00</td>\n",
       "      <td>Tempestade</td>\n",
       "      <td>Baixo</td>\n",
       "      <td>Motocicleta</td>\n",
       "      <td>Urbano</td>\n",
       "      <td>Esportes</td>\n",
       "      <td>130</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ID_pedido  anos_experiencia_agente  classificacao_agente  \\\n",
       "0  ialx566343618                        8                   4.9   \n",
       "1  akqg208421122                       10                   4.5   \n",
       "2  njpu434582536                       16                   4.4   \n",
       "\n",
       "   latitude_loja  longitude_loja  latitude_entrega  longitude_entrega  \\\n",
       "0      22.745049       75.892471         22.765049          75.912471   \n",
       "1      12.913041       77.683237         13.043041          77.813237   \n",
       "2      12.914264       77.678400         12.924264          77.688400   \n",
       "\n",
       "  data_pedido hora_pedido hora_retirada       clima           trafego  \\\n",
       "0  2022-03-19    11:30:00      11:45:00  Ensolarado              Alto   \n",
       "1  2022-03-25    19:45:00      19:50:00     Chuvoso  Congestionamento   \n",
       "2  2022-03-19    08:30:00      08:45:00  Tempestade             Baixo   \n",
       "\n",
       "       veiculo           area categoria_produto  tempo_entrega  \n",
       "0  Motocicleta         Urbano            Roupas            120  \n",
       "1      Scooter  Metropolitano       Eletronicos            165  \n",
       "2  Motocicleta         Urbano          Esportes            130  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f435f3",
   "metadata": {},
   "source": [
    "# Automatizando a análise de dados com LLMs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f8ed1bb",
   "metadata": {},
   "source": [
    "O objetivo é que a equipe de dados, ao receber esse arquivo, possa construir um modelo preditivo para prever o tempo de entrega com base nas características disponíveis. Para isso, é necessário analisar os dados, verificar os tipos de cada coluna, tratar dados nulos e duplicados, e explorar relações, como a influência dos anos de experiência no tempo de entrega.\n",
    "\n",
    "Queremos automatizar esse processo, evitando a necessidade de escrever código manualmente para calcular correlações, por exemplo. Desejamos que um LLM gere o código necessário para automatizar essas tarefas. Vamos aprender a obter esse código utilizando a ferramenta LangChain, que está em alta no campo da inteligência artificial e é útil para criar soluções e aplicações."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fd16165",
   "metadata": {},
   "source": [
    "Configurando o LangChain e o Gemini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd4efa28",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "     model=\"gemini-2.0-flash\",\n",
    "     temperature=0,\n",
    "     max_tokens=None,\n",
    "     timeout=None,\n",
    "     max_retries=2,\n",
    "     \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0afec350",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"```python\\n import pandas as pd\\n \\n\\n # Supondo que seu DataFrame já esteja carregado como 'df'\\n \\n\\n # Calcula a correlação entre as colunas 'anos_experiencia_agente' e 'tempo_entrega'\\n correlacao = df['anos_experiencia_agente'].corr(df['tempo_entrega'])\\n \\n\\n print(correlacao)\\n ```\", additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, id='run--d2328cae-8bec-4367-b5ba-7dde57a0a48c-0', usage_metadata={'input_tokens': 91, 'output_tokens': 86, 'total_tokens': 177, 'input_token_details': {'cache_read': 0}})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = [\n",
    "    (\n",
    "        \"system\",\n",
    "        \"Você é um Analista de dados prestativo que procusar padrões e ingsiths usando as boas praticas.\",\n",
    "    ),\n",
    "    (\"human\",     \"\"\" Eu tenho um dataframe chamado 'df' com as colunas 'anos_experiencia_agente' e 'tempo_entrega'.\n",
    "        Escreva o código Python com a biblioteca Pandas para calcular a correlação entre as duas colunas.\n",
    "        Retorne o Markdown para o trecho de código Python e nada mais.\n",
    "        \"\"\"\n",
    "        ),\n",
    "]\n",
    "ai_msg = llm.invoke(messages)\n",
    "ai_msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "707f580c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```python\n",
      " import pandas as pd\n",
      " \n",
      "\n",
      " # Supondo que seu DataFrame já esteja carregado como 'df'\n",
      " \n",
      "\n",
      " # Calcula a correlação entre as colunas 'anos_experiencia_agente' e 'tempo_entrega'\n",
      " correlacao = df['anos_experiencia_agente'].corr(df['tempo_entrega'])\n",
      " \n",
      "\n",
      " print(correlacao)\n",
      " ```\n"
     ]
    }
   ],
   "source": [
    "print(ai_msg.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae6ca77b",
   "metadata": {},
   "source": [
    "## Executando o código gerado com ferramentas Python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9322e7ac",
   "metadata": {},
   "source": [
    "primeiramente vamos instalar mais uma ferramenta !\n",
    "\n",
    "Para automatizar o processo de execução de código gerado por um LLM, utilizamos o LangChain, especificamente a ferramenta python-est-repltool. Vamos começar instalando o pacote experimental do LangChain, onde essa ferramenta está localizada. Para isso, executamos o seguinte comando"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ec5428a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install langchain-experimental -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "90695061",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_experimental.tools import PythonAstREPLTool"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47831a66",
   "metadata": {},
   "source": [
    "Configurando a ferramenta PythonAstREPLTool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "af507b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "ferramenta_python = PythonAstREPLTool(locals={\"df\": df})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "de1f4073",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(-0.2516410755060903)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ferramenta_python.invoke(\"df['anos_experiencia_agente'].corr(df['tempo_entrega'])\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d1eff9d",
   "metadata": {},
   "source": [
    "### Integrando a ferramenta com um LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a742d13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_com_ferramenta = llm.bind_tools([ferramenta_python], tool_choice=ferramenta_python.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "af5020c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "resposta = llm_com_ferramenta.invoke(\n",
    "    \"\"\"Eu tenho um dataframe 'df' e quero saber a correlação entre as colunas 'anos_experiencia_agente' \n",
    "    e 'tempo_entrega'\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d10ffb74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers.openai_tools import JsonOutputKeyToolsParser\n",
    "\n",
    "parser = JsonOutputKeyToolsParser(key_name=ferramenta_python.name, first_tool_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9bf4b430",
   "metadata": {},
   "outputs": [],
   "source": [
    "cadeia = llm_com_ferramenta | parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0fc5825c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'import pandas as pd\\n\\ndata = {\"anos_experiencia_agente\": [1, 2, 3, 4, 5], \"tempo_entrega\": [5, 4, 3, 2, 1]}\\ndf = pd.DataFrame(data)\\ncorrelation = df[\"anos_experiencia_agente\"].corr(df[\"tempo_entrega\"])\\nprint(correlation)\\n'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cadeia.invoke(\n",
    "    \"\"\"Eu tenho um dataframe 'df' e quero saber a correlação entre as colunas 'anos_experiencia_agente' \n",
    "    e 'tempo_entrega'\n",
    "    \n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c84ce24",
   "metadata": {},
   "source": [
    "## Criando o prompt com template"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58d97404",
   "metadata": {},
   "source": [
    "Para orientar o modelo, vamos criar um prompt usando um template. No LangChain, temos algumas opções, como o ChatPromptTemplate, que serve para criar um prompt de conversação. Imagine que haverá uma conversa em que a pessoa envia uma mensagem, a inteligência artificial gera o código, e esse código é executado pela nossa ferramenta Python. Todo esse processo ocorre de forma integrada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a37d1456",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:12: SyntaxWarning: invalid escape sequence '\\`'\n",
      "<>:12: SyntaxWarning: invalid escape sequence '\\`'\n",
      "<>:12: SyntaxWarning: invalid escape sequence '\\`'\n",
      "<>:12: SyntaxWarning: invalid escape sequence '\\`'\n",
      "C:\\Users\\Campeao Lub\\AppData\\Local\\Temp\\ipykernel_14188\\1920347851.py:12: SyntaxWarning: invalid escape sequence '\\`'\n",
      "  Não presuma que você tem acesso a nenhuma biblioteca além das bibliotecas Python integradas e pandas.\"\"\"\n",
      "C:\\Users\\Campeao Lub\\AppData\\Local\\Temp\\ipykernel_14188\\1920347851.py:12: SyntaxWarning: invalid escape sequence '\\`'\n",
      "  Não presuma que você tem acesso a nenhuma biblioteca além das bibliotecas Python integradas e pandas.\"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.2516410755060903\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "system = f\"\"\"Você tem acesso a um dataframe pandas `df`. \\\n",
    "Aqui está a saída de `df.head().to_markdown()`:\n",
    "\n",
    "\\`\\`\\`\n",
    "    {df.head().to_markdown()}\n",
    "\\`\\`\\`\n",
    "\n",
    "Dada uma pergunta do usuário, escreva o código Python para respondê-la. \\\n",
    "Retorne SOMENTE o código Python válido e nada mais. \\\n",
    "Não presuma que você tem acesso a nenhuma biblioteca além das bibliotecas Python integradas e pandas.\"\"\"\n",
    "\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([(\"system\", system), (\"human\", \"{question}\")])\n",
    "\n",
    "cadeia = prompt | llm_com_ferramenta | parser | ferramenta_python\n",
    "\n",
    "resposta = cadeia.invoke({\"question\": \"Qual é a correlação entre anos de experiência do agente e tempo de entrega?\"})\n",
    "print(resposta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "491df5bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clima\n",
      "Chuvoso       123.211825\n",
      "Ensolarado    103.664453\n",
      "Neblina       136.570833\n",
      "Nublado       138.286773\n",
      "Tempestade    123.238509\n",
      "Ventania      123.658037\n",
      "Name: tempo_entrega, dtype: float64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "resposta = cadeia.invoke({\"question\": \"Qual é média do tempo de entrega para cada tipo de clima?\"})\n",
    "print(resposta)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
